# TimberVision

![timbervision_results.png](./figures/timbervision_results.png "timbervision_results.png")

TimberVision is a dataset and framework for tree-trunk detection and tracking based on RGB images. It combines the advantages of oriented object detection and instance segmentation for optimizing robustness and efficiency, as described in the corresponding [paper](https://arxiv.org/pdf/2501.07360v1) and [poster](./figures/timbervision_poster.pdf) presented at WACV 2025. This repository contains source code, models, configuration files and documentation. Images and annotations of the TimberVision dataset are available [here](https://zenodo.org/records/14825846).


## Setup

To run any source code, clone this repository and create a conda environment using [requirements.txt](./requirements.txt).

    conda create -n timbervision python=3.11
    conda activate timbervision
    pip install -r requirements.txt

## Usage

The framework includes multiple python scripts for demonstration, evaluation and utility functions, which are summarized below. Calling any script with `-h` in the command line will display a more detailed help message including a list of available parameters.

### Demo application

[demo.py](demo.py) provides a demonstrator for detection and fusion with optional tracking on arbitrary image or video data. Only paths for input, output and models are required to run the detector and tracker with a default configuration. For usage with custom models trained on class ids different from the defaults, the `CUT`, `SIDE` and `TRUNK` values in [detector.py](./fusion/detector.py) need to be adapted accordingly. Depending on the configuration arguments, the output for each frame is either a visualization of obbs and instance-segmentation contours along with geometric features or a single-channel mask encoding class labels and object ids.

### Evaluation scripts

[eval_fusion.py](./eval_fusion.py) runs the detector and provides a quantitative evaluation of fused oriented-object-detection and instance-segmentation results by applying yolo metrics to the oriented bounding boxes of consolidated trunk instances. As inputs, the models to be evaluated and an image sequence along with ground-truth annotations in yolov8 instance-segmentation format are required.

[eval_mot.py](./eval_mot.py) runs the tracker and provides a quantitative evaluation of multi-object-tracking performance across multiple image sequences with keyframes annotated in a custom csv format (e.g. generated by [extract_instances.py](./utils/extract_instances.py)). Applied metrics include ClearMOT and ID as provided by [py-motmetrics](https://github.com/cheind/py-motmetrics).

### Dataset utilities

The [utils](./utils) directory contains multiple modules for converting annotations and input data, as well as generating visualizations and statistics.

* [calculate_stats.py](./utils/calculate_stats.py) generates dataset statistics based on yolov8 instance-segmentation annotations and corresponding images with optional filtering. They include per-class distributions of instance sizes, orientations and subset associations, as well as overall image resolutions, along with heat-map visualizations of normalized instance positions.

* [extract_instances.py](./utils/extract_instances.py) represents the algorithm used to convert the original [Scalabel](http://www.scalabel.ai/) annotations of the TimberVision dataset to multiple supported formats. They include relevant yolov8 formats, as well as custom ones for tracking evaluation. Note that both oriented-object-detection and instance-segmentation models used in this project are trained on yolov8 instance-segmentation annotations, as they are compatible with both and less restrictive regarding clipped objects compared to the official yolov8 format for oriented bounding boxes.

* [visualize_instances.py](./utils/visualize_instances.py) can be used to visualize any annotation format generated by the [annotation-conversion script](./utils/extract_instances.py) with adaptable output sizes and optional filtering.

* [extract_keyframes.py](./utils/extract_keyframes.py) can be used to sample keyframes from arbitrary video files at a given framerate (e.g. for [tracking evaluation](./eval_mot.py)).

* [convert_coco.py](./utils/convert_coco.py) converts third-party annotations in coco format to the yolov8 instance-segmentation format used for training and evaluation throughout the TimberVision framework. Optionally, an adapted format supporting multi-part contours compatible with [tracking evaluation](./eval_mot.py) can be generated.

## License

This work is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/).

[![CC BY-NC-SA 4.0][cc-by-nc-sa-image]][cc-by-nc-sa]

[cc-by-nc-sa]: http://creativecommons.org/licenses/by-nc-sa/4.0/
[cc-by-nc-sa-image]: https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png

## Citing
If you use the TimberVision dataset or framework for your research, please use the following BibTeX entry:

```BibTeX
@InProceedings{Steininger_2025_WACV,
    author    = {Steininger, Daniel and Simon, Julia and Trondl, Andreas and Murschitz, Markus},
    title     = {TimberVision: A Multi-Task Dataset and Framework for Log-Component Segmentation and Tracking in Autonomous Forestry Operations},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month     = {March},
    year      = {2025}
}
```
